{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/03_pytorch_computer_vision_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vex99np2wFVt"
   },
   "source": [
    "# 03. PyTorch Computer Vision Exercises\n",
    "\n",
    "The following is a collection of exercises based on computer vision fundamentals in PyTorch.\n",
    "\n",
    "They're a bunch of fun.\n",
    "\n",
    "You're going to get to write plenty of code!\n",
    "\n",
    "## Resources\n",
    "\n",
    "1. These exercises are based on [notebook 03 of the Learn PyTorch for Deep Learning course](https://www.learnpytorch.io/03_pytorch_computer_vision/). \n",
    "2. See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/_PibmqpEyhA). \n",
    "  * **Note:** Going through these exercises took me just over 3 hours of solid coding, so you should expect around the same.\n",
    "3. See [other solutions on the course GitHub](https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/solutions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GaeYzOTLwWh2",
    "outputId": "17dd5453-9639-4b01-aa18-7ddbfd5c3253"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec 12 22:06:46 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.147.05   Driver Version: 525.147.05   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100S-PCI...  Off  | 00000000:18:00.0 Off |                    0 |\n",
      "| N/A   44C    P0    40W / 250W |   1344MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100S-PCI...  Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   48C    P0    41W / 250W |  27008MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100S-PCI...  Off  | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    25W / 250W |     80MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100S-PCI...  Off  | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   53C    P0    43W / 250W |  27008MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2338      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    0   N/A  N/A   3795694      C   ...conda3/envs/rl/bin/python     1264MiB |\n",
      "|    1   N/A  N/A      2338      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A   3536500      C   ...3/envs/llm-pbe/bin/python    26992MiB |\n",
      "|    2   N/A  N/A      2338      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    3   N/A  N/A      2338      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    3   N/A  N/A   3537871      C   ...3/envs/llm-pbe/bin/python    26992MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "DNwZLMbCzJLk",
    "outputId": "9c150c50-a092-4f34-9d33-b45247fb080d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import torch\n",
    "import torch\n",
    "\n",
    "# Exercises require PyTorch > 1.10.0\n",
    "print(torch.__version__)\n",
    "\n",
    "# TODO: Setup device agnostic code\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSFX7tc1w-en"
   },
   "source": [
    "## 1. What are 3 areas in industry where computer vision is currently being used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VyWRkvWGbCXj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBK-WI6YxDYa"
   },
   "source": [
    "## 2. Search \"what is overfitting in machine learning\" and write down a sentence about what you find. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d1rxD6GObCqh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XeYFEqw8xK26"
   },
   "source": [
    "## 3. Search \"ways to prevent overfitting in machine learning\", write down 3 of the things you find and a sentence about each. \n",
    "> **Note:** there are lots of these, so don't worry too much about all of them, just pick 3 and start with those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ocvOdWKcbEKr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKdEEFEqxM-8"
   },
   "source": [
    "## 4. Spend 20-minutes reading and clicking through the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
    "\n",
    "* Upload your own example image using the \"upload\" button on the website and see what happens in each layer of a CNN as your image passes through it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TqZaJIRMbFtS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvf-3pODxXYI"
   },
   "source": [
    "## 5. Load the [`torchvision.datasets.MNIST()`](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SHjeuN81bHza"
   },
   "outputs": [],
   "source": [
    "# Import PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Import torchvision \n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Import matplotlib for visualization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:17<00:00, 566265.38it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 155101.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:01<00:00, 1502385.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 3053948.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup training data\n",
    "train_data = datasets.MNIST(\n",
    "    root=\"data\", # where to download data to?\n",
    "    train=True, # get training data\n",
    "    download=True, # download data if it doesn't exist on disk\n",
    "    transform=ToTensor(), # images come as PIL format, we want to turn into Torch tensors\n",
    "    target_transform=None # you can transform labels as well\n",
    ")\n",
    "\n",
    "# Setup testing data\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False, # get test data\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
      "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
      "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
      "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
      "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
      "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
      "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
      "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
      "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
      "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
      "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
      "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
      "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
      "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
      "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]]) 5\n",
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "img, label = train_data[0]\n",
    "print(img, label)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0 - zero',\n",
       " '1 - one',\n",
       " '2 - two',\n",
       " '3 - three',\n",
       " '4 - four',\n",
       " '5 - five',\n",
       " '6 - six',\n",
       " '7 - seven',\n",
       " '8 - eight',\n",
       " '9 - nine']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxZW-uAbxe_F"
   },
   "source": [
    "## 6. Visualize at least 5 different samples of the MNIST training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "QVFsYi1PbItE"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAJxCAYAAAC5R4+PAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA3yklEQVR4nO3dZ5hV5dk24HsA6QKCWBAFAUVFDTY0KsXeAq9BsAfEelhfO/E1KNiiqLHEEmOsGLsSE3sJKBaM3WiMYkFRI9gQEUFx1vfDz0kmuNYDm9kzDHOex8EP97WfZz1DsuBiseemIsuyLAAAgFyN6voAAACwpFOaAQAgQWkGAIAEpRkAABKUZgAASFCaAQAgQWkGAIAEpRkAABKUZgAASFCaG6ABAwbEgAED6voYQA1yX0P9MnHixKioqIiJEyeWvPb222+v+YORS2muRc8//3wMGjQo2rdvHy1btox11103Lr744ro+FrAY3NdQP0yZMiX23HPP6Ny5c7Rs2TLWWmutOO2002LOnDl1fbSyuvHGG+PCCy+s62MsFZrU9QEaigcffDAGDhwYG2ywQYwaNSpat24db731Vrz//vt1chZg8bmvoX6YNm1a9OnTJ9q2bRtHHHFEtG/fPp566qk49dRT47nnnou77rqr1s/Ur1+/+Prrr6Np06Zlvc6NN94Yr7zyShx99NFlvU5DoDTXglmzZsWwYcNil112idtvvz0aNarbB/zlvkGhIXBfQ/0xbty4mDlzZjz++OPRq1eviIg4+OCDo7KyMq6//vr4/PPPY7nllqvVMzVq1CiaN29eq9dk8fh4Ri248cYbY/r06XHmmWdGo0aN4quvvorKysqyXOujjz6KESNGROfOnaNZs2ax8sorx//8z//E1KlTq97z3599HD58eDRv3jxee+21anvtsMMOsdxyy8WHH35YlrNCfea+hvpj1qxZERGx4oorVnt95ZVXjkaNGtX4Hzr/+c9/xpAhQ6J9+/bRvHnz2HjjjePPf/5ztffkfab50ksvjW7dukWLFi2iT58+MWnSpNzvWaisrIwzzzwzOnfuHM2bN49tttkm3nzzzap8wIABcc8998S7774bFRUVUVFREV27dq3Rr7UhUZprwcMPPxxt2rSJDz74IHr27BmtW7eONm3axKGHHhpz586t0WvttttuMX78+BgxYkRcdtllcdRRR8WXX34Z7733Xu6aiy66KDp27BjDhw+P7777LiIirrjiinjwwQfjt7/9bXTq1KlGzwhLA/c11B8/FM4DDjggXnzxxZg2bVrccsstcfnll8dRRx0VrVq1qrFrvfrqq7HZZpvFa6+9Fr/85S/j/PPPj1atWsWuu+4a48ePL1x7+eWXxxFHHBGdO3eOsWPHRt++fWPXXXfN/cjX2WefHePHj4/jjz8+TjrppJg8eXLss88+VfnJJ58cvXv3juWXXz7GjRsX48aN8/nmxZFRduuvv37WsmXLrGXLltmRRx6Z3XHHHdmRRx6ZRUS255571th1Pv/88ywisnPPPbfwff3798/69+9f7bUHHnggi4jsjDPOyN5+++2sdevW2a677lpjZ4Oljfsa6pfTTz89a9GiRRYRVT9OPvnkGr/ONttsk6233nrZ3Llzq16rrKzMNt9882yNNdaoem3ChAlZRGQTJkzIsizL5s2bl3Xo0CHbZJNNsm+//bbqfddee20WEdXu7x/Wrr322tm8efOqXr/ooouyiMj+/ve/V722yy67ZF26dKnxr7Mh8qS5FsyePTvmzJkTw4YNi4svvjgGDx4cF198cRxyyCFx8803x5QpU2rkOi1atIimTZvGxIkT4/PPP1+ktdtvv30ccsghcdppp8XgwYOjefPmccUVV9TIuWBp5L6G+qVr167Rr1+/+P3vfx933HFH7L///nHWWWfFJZdcUmPX+Oyzz+Kvf/1r7L777vHll1/GJ598Ep988kl8+umnscMOO8SUKVPigw8++NG1zz77bHz66adx0EEHRZMm//6Ws3322Sf389YjRoyo9tGSvn37RkTE22+/XWNfE/+mNNeCFi1aRETEXnvtVe31vffeOyIinnrqqdy1s2fPjo8++qjqx8cff5z73mbNmsU555wT9913X6y44orRr1+/GDt2bHz00UcLdc7zzjsv2rdvHy+++GJcfPHFscIKKyzUOmiI3NdQf9x8881x8MEHxx/+8Ic46KCDYvDgwXHVVVfF8OHDY+TIkfHpp5/mrl2U+/XNN9+MLMti1KhR0bFjx2o/Tj311IiImDFjxo+ufffddyMiokePHtVeb9KkSe7nkFdbbbVq//1DuV7UP2CzcJTmWvDDZwf/+xsQfvjNq+j/3Oedd16svPLKVT822WSTwmsdffTR8cYbb8Svf/3raN68eYwaNSrWXnvteOGFF5LnfOGFF6pu5r///e/J90ND5r6G+uOyyy6LDTbYIDp37lzt9UGDBsWcOXMK76VFuV9/+Gbg448/Ph566KEf/fHfpXhxNG7c+Edfz7Ksxq7Bvxk5Vws22mijeOihh6q+YegHP3z3eseOHXPXDhs2LLbccsuq//7h6VaR7t27x3HHHRfHHXdcTJkyJXr37h3nn39+3HDDDblrvvrqqxgxYkSss846sfnmm8fYsWPj5z//efI3c2io3NdQf0yfPv1HP+Lw7bffRkTE/Pnzc9cuyv3arVu3iIhYZpllYtttt12kM3bp0iUivn9avdVWW1W9Pn/+/Jg6dWqsv/76i7TfDyoqKkpax4KU5lqw++67x9lnnx1XXXVVbL311lWv/+EPf4gmTZoU/tO33bp1q7oJU+bMmbPA3Mfu3bvHsssuG/PmzStcO3LkyHjvvfdi8uTJ0bNnz3jkkUdi+PDh8cILL0SzZs0W6vrQkLivof5Yc80148EHH4w33ngj1lxzzarXb7rppmjUqFFhIV2U+3WFFVaIAQMGxBVXXBFHHnlkrLzyytXyjz/+OPcP1BtvvHF06NAhrrzyyhgxYkTV55r/+Mc/LtbHLVq1ahVffPFFyev5N6W5FmywwQax//77x9VXXx3z58+P/v37x8SJE+O2226Lk046qcZGP73xxhuxzTbbxO677x7rrLNONGnSJMaPHx/Tp0+PPffcM3fdX//617jsssvi1FNPjQ033DAiIq655poYMGBAjBo1KsaOHVsj54Olifsa6o8TTjgh7rvvvujbt28cccQR0aFDh7j77rvjvvvuiwMPPLBGRzBeeumlseWWW8Z6660XBx10UHTr1i2mT58eTz31VLz//vvx0ksv/ei6pk2bxujRo+PII4+MrbfeOnbfffeYOnVqXHvttdG9e/eSnxhvtNFGccstt8Sxxx4bm2yySbRu3ToGDhy4OF9iw1XX4zsaim+++SYbPXp01qVLl2yZZZbJevTokV1wwQU1eo1PPvkkO/zww7O11lora9WqVda2bdts0003zW699dZq7/vP0VSzZs3KunTpkm244YbVRtxkWZYdc8wxWaNGjbKnnnqqRs8JSwv3NdQfTz/9dLbTTjtlK620UrbMMstka665ZnbmmWcucI/UhLfeeisbNmxY1bVWWWWV7Gc/+1l2++23V73nv0fO/eDiiy/OunTpkjVr1izr06dP9sQTT2QbbbRRtuOOOy6w9rbbbqu29p133skiIrvmmmuqXps9e3a29957Z+3atcsiwvi5xVCRZT4tDgCwJKqsrIyOHTvG4MGD48orr6zr4zRopmcAACwB5s6du8Dki+uvvz4+++yzwu+ToHZ40gwAsASYOHFiHHPMMTF06NDo0KFDPP/883HVVVfF2muvHc8991y1f8iE2ucbAQEAlgBdu3aNVVddNS6++OL47LPPon379jFs2LA4++yzFeYlgCfNAACQ4DPNAACQoDQDAECC0gwAAAkL/Y2A/u1yWHRL+rcMuK9h0bmvYemzMPe1J80AAJCgNAMAQILSDAAACUozAAAkKM0AAJCgNAMAQILSDAAACUozAAAkKM0AAJCgNAMAQILSDAAACUozAAAkKM0AAJDQpK4PAED90L9//9xs8803z81+/etfl+M4ALXKk2YAAEhQmgEAIEFpBgCABKUZAAASlGYAAEhQmgEAIMHIOXJ17tw5N+vZs2fh2vHjx+dmrVu3zs0qKioK933yySdzsy222KJwLRDRuHHj3Oycc84pXHvYYYflZhdccEHJZwKoDzxpBgCABKUZAAASlGYAAEhQmgEAIEFpBgCABKUZAAASjJxr4EaOHJmb9evXLzfbcccdS75mlmUlZRERlZWVJV8XiLj44otzs0MPPbRw7VVXXZWbjRo1quQzQUMxYMCAkrKIiP79+5d0zUcffbSkdSmjR48uy75LMk+aAQAgQWkGAIAEpRkAABKUZgAASFCaAQAgQWkGAIAEpRkAABIqstRg3B/eWFFR7rM0aE2bNi3MmzTJH6m9/fbb52Ynnnhi4b4bbLBByWeqC1988UVudtxxxxWuveaaa2r6OEkLeXvVGfd1/bTccssV5ueff35uNnTo0NwsNXf1oosuys3mz59fuHZp4r6mSNG85QkTJtTeQcpsafv/2cLc1540AwBAgtIMAAAJSjMAACQozQAAkKA0AwBAgtIMAAAJ+XPMqHGdOnXKza688srCtTvuuGNNH6deevXVV3OzuhgpB+Wy2mqr5WZ33nln4dqicZGDBg3KzZamcVhQLkUj5SLKdx+NGTOmLPv2798/N0t9rQ2NJ80AAJCgNAMAQILSDAAACUozAAAkKM0AAJCgNAMAQIKRczXshBNOyM369euXmxkpt3B+97vf1fURoMbsuuuuudnll1+em3388ceF+xb9evLhhx8mzwXkK9dIuYqKirLsmzJ69OjczMi56jxpBgCABKUZAAASlGYAAEhQmgEAIEFpBgCABKUZAAASlGYAAEhokHOaU7MQ27dvn5sddthhhWtPPPHE3Kxly5bFB6tHvvzyy8J8l112KXltkVdeeaXktVAOyy67bG521llnFa494IADcrNHHnkkNxs6dGjhvnPnzi3MgWJFs4tTJk6cmJtttdVWJe9bF8aMGVPXR1iieNIMAAAJSjMAACQozQAAkKA0AwBAgtIMAAAJSjMAACQ0yJFzLVq0KMxnzJhRSyepe3/5y19ys6KxVRdeeGHhvpMnTy71SLDEWXHFFXOzW2+9NTfr06dP4b5jx47NzU499dT0wYCyWJz779FHH63Bk5Rf0Xi9xRm9tzTypBkAABKUZgAASFCaAQAgQWkGAIAEpRkAABKUZgAASFCaAQAgoUHOaV7aPPnkk7nZDTfcULi2KP/qq69KPhPUJ6uttlphPn78+NysXbt2udkWW2xRuO/zzz9fmAPlYwbx94p+HormVffv379w36222qrUIy2xPGkGAIAEpRkAABKUZgAASFCaAQAgQWkGAIAEpRkAABLq9ci55s2b52a//OUvc7O99967HMdZLJ9//nlh/s477+RmQ4YMyc2mT59e8pkWxyqrrJKbFY2ymzlzZhlOAxE9evTIzR544IHCtcsss0xuNmDAgNzs7bffTp5rabHxxhvnZgcffHDh2qL7ftSoUYVr582bV5hDnokTJ+ZmRaPW6pvUaL1Sv9YxY8aUtK4+86QZAAASlGYAAEhQmgEAIEFpBgCABKUZAAASlGYAAEio1yPntthii9wsNaaoLkydOjU3O+CAAwrXPvPMM7lZ0ci5uvLb3/42N3v88cdzs1tuuaVw3xkzZuRm9913X/pgLLXatGlTmF999dW52ccff1y4ds8998zNiu7r+mbFFVcszEeOHJmbHXHEEbnZt99+W7hv0Ui/9ddfv3DtjjvuWJhDnqKRc4ujf//+Zdm3aLxlUbY44/OKxsqV6+dvSeZJMwAAJCjNAACQoDQDAECC0gwAAAlKMwAAJCjNAACQoDQDAEBCRZZl2UK9saKi3GdZZNtss01u9uCDD9biSf5t9uzZudnAgQNzs27duhXuu/POO+dmu+22W/pgS4miebqHH3544do77rijpo+TtJC3V51ZEu/rIr17987Nbr311sK1b731Vm525JFHFq598803C/MlzbLLLpub9evXLzc7/fTTC/ft0aNHbnbggQfmZk8//XThvquuumpulpq/XvS1lov7eulXNPd4woQJJe9bNNu46JqLIzVPeauttirLdeubhbmvPWkGAIAEpRkAABKUZgAASFCaAQAgQWkGAIAEpRkAABLq9ci5ovFj7du3r8WT/FtlZWVu9q9//Ss3a9euXeG+rVq1KvVIDcaXX35ZmBeN7XvyySdr+jgRYTRVKVZZZZXc7LnnnsvNpkyZUrjvdtttl5vNnTs3fbAlSGrM2mmnnZabHXbYYbnZH/7wh8J9f/Ob3+RmRSP9Utq2bZubvf3224VrO3ToUPJ1S+W+btjq6n//otFxxsYtPiPnAACgBijNAACQoDQDAECC0gwAAAlKMwAAJCjNAACQ0KSuD7A4ikYN1dVImEaN8v8cUjRKi8WXGsPVrFmzWjoJRVq0aFGY//GPf8zNpk2blpttu+22hfvOmzev+GBLmKKfp9RouE033TQ323PPPXOz8ePHpw9Wgo4dOxbmkydPzs0efvjhmj4OLJai0W8REQMGDCjLdR999NGy7MvC86QZAAASlGYAAEhQmgEAIEFpBgCABKUZAAASlGYAAEhQmgEAIKFez2kG6p9+/foV5kUzhjfZZJPcrL7NYU4ZOXJkbrbxxhsXrt1mm21ys7feeqvkM62wwgq52XHHHZebHXjggYX7vvvuuyWvhVIVzVM+9dRTS1pXTkVnKpodnZorzcLzpBkAABKUZgAASFCaAQAgQWkGAIAEpRkAABKUZgAASKjIsixbqDdWVJT7LIussrIyN1vIL6ve+Oabb3Kzf/zjH7nZ2LFjC/d97LHHcrO11lorNzvllFMK902NFSuH6dOnF+aDBg3KzZ599tmaPk5ELPn/P6yL+/rNN98szIvGjxWNUquPiu6Tu+++OzfbcMMNC/ct+jleccUVc7Odd965cN/Ro0fnZs2bN8/NikZlRURcc801udmSOErQfb10mDBhQm62OGPlttpqq5LWFZ1ncYwZM6YwL7qvG5KFua89aQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEur1yLlbb701N9ttt91q8STlN3PmzNzsjDPOKHnfjh075mYjR44sed+6cOaZZxbmqTF55WA01YJSPyeDBw/OzcaPH1/Tx6lTzzzzTG728MMP52bnnHNO4b7HHHNMSVnr1q0L9y060xFHHJGbvfHGG4X71jfu6/ohNcKt1LFy5fr5TZ2naHTj4ozImzhxYm5W6vi8+sjIOQAAqAFKMwAAJCjNAACQoDQDAECC0gwAAAlKMwAAJCjNAACQUK/nNG+zzTa52YMPPliLJ6G2/OMf/8jNUrO562JWrHmuC6qsrCzMN9tss9zsb3/7W00fZ7GtuOKKuVnz5s0L1xbNaZ43b15u9t577xXu+9Of/jQ3mz17dm52wQUXFO47duzY3Oyrr74qXLs0cV8vOYpmMadmF9e3+cRFX0+5ZjiPGTMmNxs9enTJ+y6JzGkGAIAaoDQDAECC0gwAAAlKMwAAJCjNAACQoDQDAEBCk7o+wOL44osvcrMPPvggN1tllVXKcRwW0ocffpib7bvvvoVrn3rqqdzsm2++KflMLDkuu+yy3GzcuHG52eTJk8txnIiI2HDDDXOzs88+OzdbdtllS77m/Pnzc7OiMVsREdddd11udt999+Vm06ZNSx8MliCLM07t0UcfrbmD1IKiEXlFI+eoOZ40AwBAgtIMAAAJSjMAACQozQAAkKA0AwBAgtIMAAAJFVmWZQv1xoqKcp+lRm233Xa52VVXXVW41ki6xXf++efnZn/9619zs/vvv78cx6kzC3l71Zm6uK+HDBlSmKfGDtYnM2fOLMwff/zx3Oyuu+7KzT7++ONSj0QNcF/XntGjRxfmizNqbcyYMSWtS52paAze4ozIK9dYuaJRdltttVVZrrkkWpj72pNmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgISldk5zkc0337wwnzRpUi2dpO5NmzYtNxsxYkTJ+xbNn/32229L3re+Mc8Vlj7u6yXHhAkTcrPFmYnckBTNYi6a4by0MacZAABqgNIMAAAJSjMAACQozQAAkKA0AwBAgtIMAAAJDXLkHNQWo6lg6eO+rh9Gjx5dmPfv3z83q4txdWPGjCl5bdFouIY0Nm5xGDkHAAA1QGkGAIAEpRkAABKUZgAASFCaAQAgQWkGAIAEpRkAABLMaYYyMs8Vlj7ua1j6mNMMAAA1QGkGAIAEpRkAABKUZgAASFCaAQAgQWkGAIAEpRkAABKUZgAASFCaAQAgQWkGAIAEpRkAABKUZgAASFCaAQAgQWkGAIAEpRkAABKUZgAASFCaAQAgQWkGAIAEpRkAABKUZgAASFCaAQAgQWkGAIAEpRkAABKUZgAASFCaAQAgQWkGAIAEpRkAABKUZgAASKjIsiyr60MAAMCSzJNmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAKLP7778/evfuHc2bN4+KioqYOXNmXR+JRaQ0l8EzzzwTRxxxRPTq1StatWoVq622Wuy+++7xxhtv1Pi1nnzyyRg9erSbD8po3rx5MXLkyOjUqVO0aNEiNt1003jooYfq+lhADTrzzDOjoqIi1l133Rrf+9NPP43dd989WrRoEZdeemmMGzcuWrVqVePXobwqsizL6voQS5shQ4bEE088EUOHDo31118/Pvroo7jkkkti9uzZMXny5Bq9Ic8777w44YQT4p133omuXbvW2L7Av+21115x++23x9FHHx1rrLFGXHvttfHMM8/EhAkTYsstt6zr4wGL6f3334+ePXtGRUVFdO3aNV555ZUa3f/++++PnXbaKR566KHYdttta3Rvak+Tuj7A0ujYY4+NG2+8MZo2bVr12h577BHrrbdenH322XHDDTfU4emARfG3v/0tbr755jj33HPj+OOPj4iIYcOGxbrrrhsnnnhiPPnkk3V8woX31VdfeboFP+L444+PzTbbLL777rv45JNPanz/GTNmREREu3btanzvlPnz50dlZWW1TkJpfDyjDDbffPMF/s+5xhprRK9eveK1116rseuMHj06TjjhhIiIWH311aOioiIqKipi6tSpMXjw4Nhwww2rvX/gwIFRUVERf/7zn6tee/rpp6OioiLuu+++qtfefvvtGDp0aLRv3z5atmwZm222Wdxzzz01dm6oT26//fZo3LhxHHzwwVWvNW/ePA444IB46qmnYtq0aTVynYkTJ1bdw//947//Fum+++6Lvn37RqtWrWLZZZeNXXbZJV599dVq79lvv/2idevW8dZbb8XOO+8cyy67bOyzzz4R8X15Pu6442LVVVeNZs2aRc+ePeO8884Lf/FIQ/TYY4/F7bffHhdeeGFZ9h8wYEAMHz48IiI22WSTqKioiP32268qv+2222KjjTaKFi1axPLLLx/77rtvfPDBBwvsMWDAgAX23m+//ar9+jB16tSoqKiI8847Ly688MLo3r17NGvWLP7xj3+U40trcDxpriVZlsX06dOjV69eNbbn4MGD44033oibbropLrjgglh++eUjIqJjx47Rt2/fuOuuu2LWrFnRpk2byLIsnnjiiWjUqFFMmjQpBg0aFBERkyZNikaNGsUWW2wRERHTp0+PzTffPObMmRNHHXVUdOjQIa677roYNGhQ3H777fHzn/+8xs4P9cELL7wQa665ZrRp06ba63369ImIiBdffDFWXXXVxb7O2muvHePGjav22syZM+PYY4+NFVZYoeq1cePGxfDhw2OHHXaIc845J+bMmROXX355bLnllvHCCy9U+w10/vz5scMOO8SWW24Z5513XrRs2TKyLItBgwbFhAkT4oADDojevXvHAw88ECeccEJ88MEHccEFFyz21wL1xXfffRdHHnlkHHjggbHeeuuV5Ronn3xy9OzZM37/+9/HaaedFquvvnp07949IiKuvfbaGDFiRGyyySbx61//OqZPnx4XXXRRPPHEE/HCCy+U/GT6mmuuiblz58bBBx8czZo1i/bt29fgV9SAZdSKcePGZRGRXXXVVTW677nnnptFRPbOO+9Ue/2ZZ57JIiK79957syzLspdffjmLiGzo0KHZpptuWvW+QYMGZRtssEHVfx999NFZRGSTJk2qeu3LL7/MVl999axr167Zd999V6PnhyVdr169sq233nqB11999dUsIrLf/e53ZbluZWVl9rOf/Sxr3bp19uqrr2ZZ9v292K5du+yggw6q9t6PPvooa9u2bbXXhw8fnkVE9stf/rLae//0pz9lEZGdccYZ1V4fMmRIVlFRkb355ptl+XpgSXTJJZdkbdu2zWbMmJFlWZb1798/69WrV41f55prrskiInvmmWeqXvvmm2+yFVZYIVt33XWzr7/+uur1u+++O4uI7JRTTql6rX///ln//v0X2Hf48OFZly5dqv77nXfeySIia9OmTdXXRM3x8Yxa8M9//jMOP/zw+OlPf1r1VzTltsEGG0Tr1q3jsccei4jvnyh37tw5hg0bFs8//3zMmTMnsiyLxx9/PPr27Vu17t57740+ffpU++am1q1bx8EHHxxTp071Vzw0OF9//XU0a9ZsgdebN29elZfD6aefHnfffXdce+21sc4660RExEMPPRQzZ86MvfbaKz755JOqH40bN45NN900JkyYsMA+hx56aLX/vvfee6Nx48Zx1FFHVXv9uOOOiyzLqn1UC5Zmn376aZxyyikxatSo6NixY61f/9lnn40ZM2bEYYcdVvXrSUTELrvsEmuttdZifSxyt912q5OvaWnn4xll9tFHH8Uuu+wSbdu2rfpsZJGvv/46vvjii2qvrbTSSot83caNG8dPf/rTmDRpUkR8X5r79u0bW265ZXz33XcxefLkWHHFFeOzzz6rVprffffd2HTTTRfYb+21167KyzGOB5ZULVq0iHnz5i3w+ty5c6vyPLNnz47Zs2dX/Xfjxo0X6jey+++/P8aMGRMnnXRS7LbbblWvT5kyJSIitt566x9d998fIWnSpEl07ty52mvvvvtudOrUKZZddtlqr//nPQ4Nwa9+9ato3759HHnkkYu8ttR7+z/9cK/17NlzgWyttdaKxx9/fJHP9YPVV1+95LXkU5rL6IsvvoiddtopZs6cGZMmTYpOnTol19xyyy0xYsSIaq9lJX5zzpZbbhlnnnlmzJ07NyZNmhQnn3xytGvXLtZdd92YNGlSrLjiihER1UozUN3KK6+8wDflRET861//iogovK/PO++8GDNmTNV/d+nSJaZOnVp4vXfeeSf22Wef2G677eKMM86ollVWVkbE959r/rE/TDdpUv2X9GbNmkWjRv5CEf7blClT4ve//31ceOGF8eGHH1a9Pnfu3Pj2229j6tSp0aZNm9zPApdyby+OioqKH+0C33333Y++v+gP85ROaS6TuXPnxsCBA+ONN96Ihx9+uOqvV1N22GGHRfpHEyoqKnKzvn37xjfffBM33XRTfPDBB1XluF+/flWlec0116wqzxHf3/ivv/76Anv985//rMqhIendu3dMmDCh6ptqf/D0009X5XmGDRtW7aNOqd/Ivv766xg8eHC0a9cubrrppgUK7w/fPLTCCiuUPOu1S5cu8fDDD8eXX35Z7Wmze5yG5IMPPojKyso46qijFvioUsT3T2r/93//N3eixqLe2z/mh3vt9ddfX+Bvj15//fVq9+Jyyy0Xb7/99gJ7+JuhWla3H6leOs2fPz8bNGhQ1qRJk+yee+4p67Uuv/zyLCKyF154YYHsq6++ypZZZpmsZ8+eWfv27bPKysosy7LslltuyVq1apWtssoq2QEHHFBtzQ/fCPjkk09WvTZ79uysW7duvhGQBmny5MlZRGTnnntu1Wtz587NevToUe2bamvCsGHDspYtW2YvvfTSj+ZffPFF1qZNm6x///7ZN998s0D+n9/4M3z48KxVq1YLvOeHbwQ866yzqr2+xx57+EZAGoyPP/44Gz9+/AI/evXqla222mrZ+PHjs5dffrnGrlf0jYDrr79+Nnfu3KrX77333gW+EfD444/PmjVrVu0ef/HFF7NGjRr96DcC/uevV9QcT5rL4Ljjjos///nPMXDgwPjss88W+MdM9t133xq71kYbbRQR34+02XPPPWOZZZaJgQMHRqtWraJly5ax0UYbxeTJk6tmNEd8/6T5q6++iq+++mqBj2b88pe/jJtuuil22mmnOOqoo6J9+/Zx3XXXxTvvvBN33HGHv+qlwdl0001j6NChcdJJJ8WMGTOiR48ecd1118XUqVPjqquuqrHr3HPPPXH99dfHbrvtFi+//HK8/PLLVVnr1q1j1113jTZt2sTll18ev/jFL2LDDTeMPffcMzp27Bjvvfde3HPPPbHFFlvEJZdcUnidgQMHxlZbbRUnn3xyTJ06NX7yk5/Egw8+GHfddVccffTRVU+zYWm2/PLLx6677rrA6z88Wf6xrKYts8wycc4558SIESOif//+sddee1WNnOvatWscc8wxVe/df//94ze/+U3ssMMOccABB8SMGTPid7/7XfTq1StmzZpV9rPy/9V1a18a9e/fP4uI3B817fTTT89WWWWVrFGjRguMnzvhhBOyiMjOOeecamt69OiRRUT21ltvLbDfW2+9lQ0ZMiRr165d1rx586xPnz7Z3XffXePnhvri66+/zo4//vhspZVWypo1a5Ztsskm2f3331+j1/jhSdSP/fjPJ0lZlmUTJkzIdthhh6xt27ZZ8+bNs+7du2f77bdf9uyzz1a9J+9Jc5Z9P7rumGOOyTp16pQts8wy2RprrJGde+65VX8bBQ1VbY6c+8Ett9ySbbDBBlmzZs2y9u3bZ/vss0/2/vvvL/C+G264IevWrVvWtGnTrHfv3tkDDzyQO3LOk+byqMgy/wQUAAAU8XftAACQoDQDAECC0gwAAAlKMwAAJCjNAACQoDQDAECC0gwAAAkL/S8C/vCvyQELb0kfg+6+hkXnvoalz8Lc1540AwBAgtIMAAAJSjMAACQozQAAkKA0AwBAgtIMAAAJSjMAACQozQAAkKA0AwBAgtIMAAAJSjMAACQozQAAkKA0AwBAgtIMAAAJSjMAACQozQAAkKA0AwBAgtIMAAAJSjMAACQozQAAkKA0AwBAgtIMAAAJSjMAACQozQAAkKA0AwBAgtIMAAAJSjMAACQ0qesDsHA6dOiQm5122mm52XrrrVe479VXX52b3XnnnbnZrFmzCvcFAFiaeNIMAAAJSjMAACQozQAAkKA0AwBAgtIMAAAJSjMAACQozQAAkFCRZVm2UG+sqCj3WRq0tdZaqzC/++67c7Nu3brV9HEiIuLKK6/MzQ455JCyXHNps5C3V51xX9dPp556amF+4okn5mYtWrQo+bovvvhibjZkyJDcbObMmYX7fvbZZyWeqG64rxdd06ZNc7MrrrgiNxs+fHjhvn/6059ysxEjRhSu/eKLLwpzGpaFua89aQYAgASlGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEoycq0WNGzfOzZ599tnCtT/5yU9ys08++SQ3S416atKkSW622mqr5WaPPPJI4b677bZbbjZ79uzCtUsTo6kohzXXXLMwv+aaa3KzTTfdtKaPk3TjjTcW5tddd11u9vzzzxeu/fzzz0s60+JwXy+65ZZbLjcr+j1scfTp06cwf+6558py3Ybi0EMPLcw7deqUm51++umFa7/55puSzrQ4jJwDAIAaoDQDAECC0gwAAAlKMwAAJCjNAACQoDQDAECCkXO1qGnTprnZ3LlzS9534MCBudk999xTuLZr16652dtvv13qkWLo0KG52R133FHyvvWN0VQU6dKlS2623Xbb5WZ77LFH4b5bbbVVyWda0hT9PERETJgwoZZO8m/u60VXFyPnUuMKN9lkk7Jcd2my8sor52Y33XRT4dq+ffvmZvvuu2/h2tTe5WDkHAAA1AClGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIaFLXB2hI9ttvv9zs22+/LVxbNKt00qRJpR4pZs6cmZu9+eabuVmPHj0K923VqlWpR4KlxkorrVSYjx07Njfbbbfdavo4i23atGm52VNPPZWb7b777iVfc//99y/MX3zxxdzs888/L/m6QMTs2bNzs48//rgWT7Jk8KQZAAASlGYAAEhQmgEAIEFpBgCABKUZAAASlGYAAEgwcq6GtW/fPjfbd999c7Ozzz67cN/HHnus5DMVKXXk3BprrFG4b8eOHUs9EixxTj/99Nyse/fuuVnbtm0L991hhx1KPlM5zJo1qzA/6KCDcrMpU6aUfN2ikXR77bVX4dpRo0blZkbOweJp165dbta5c+faO8gSwpNmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACBBaQYAgARzmmvYeuutl5ttttlmudnOO+9cjuOUTZZlhfnUqVNr5yCwkA499NDcbNiwYYVr11lnndysVatWJZ9pSZP6dWjy5Mkl7fv3v/+9MC+a05xy55135mYbbrhhyfsCEauuumpu1qdPn5L3HTt2bGF+0003lbx3OXnSDAAACUozAAAkKM0AAJCgNAMAQILSDAAACUozAAAkGDlXw7bddtvcrGhM2+zZs8txnKSOHTvmZr179669g8Bi2nfffQvzohFHLVq0qOnjREREZWVlYf6Xv/wlNzvkkENys1NOOaVw36K1jRs3zs1eeumlwn1LddFFFxXma6+9dm629957F65df/31SzoTkFY0PvbJJ58sXLv55pvnZp06dSr1SHXKk2YAAEhQmgEAIEFpBgCABKUZAAASlGYAAEhQmgEAIMHIuRo2d+7cuj7CItlss81ys5VWWqnkfVOjtqAUrVu3zs26d+9euLYuxsrdddddhWuHDh1a0jWPOuqowrxLly652S677FLSNRfHnDlzCvN58+bV0kmoK7169arrI1CCDz/8MDd78cUXC9cWjZw7/PDDSz1SnfKkGQAAEpRmAABIUJoBACBBaQYAgASlGQAAEpRmAABIUJoBACDBnOYa9vjjj9f1Earp0KFDYX7KKaeUtO+rr75amI8fP76kfaFVq1a52dFHH52bjRo1qgyn+d6kSZNys48++ig322uvvcpxnKS//e1vuVnRXGnz1SmXkSNH1vo1Kyoqav2aS5sePXrkZltvvXXJ+37xxRclr61LnjQDAECC0gwAAAlKMwAAJCjNAACQoDQDAECC0gwAAAlGztWwovFTM2fOrL2D/H/bb799Yb7RRhuVtO++++5b0jpIKRpN9X//93+1eJJ/KzpT0Xi3unLmmWfW9RGq6dOnT2Heq1evWjoJ5XL++ecX5jvuuGMtneTfevfuXZjPmTMnN9t9991zs7vvvrtw31VWWSU3a9Qo/1ll6j4p+rUmtbZURWP7pk2bVrh2rbXWqunj1DlPmgEAIEFpBgCABKUZAAASlGYAAEhQmgEAIEFpBgCABCPnatjrr7+emxWNoVkcQ4YMyc3Gjh1buPbbb7/NzY499tjc7OWXX04fDErwq1/9KjerrKwsyzWvu+66wvzdd98ty3Ubim222aYwL9e4LGpP0e8XEeW7d4sUjUuLiGjWrFludswxx+Rm3bp1K9x3zz33zM0aN26cm2288caF+z777LMlr13SNG3atK6PUBJPmgEAIEFpBgCABKUZAAASlGYAAEhQmgEAIEFpBgCABKUZAAASKrIsyxbqjYl5h5RX9+7dc7OJEyfmZqnZ0I888khutt122yXPRbGFvL3qzJJ4XxfNc12cWa/jxo3LzU4++eTCtR9++GHJ120o+vfvn5tddtllhWt79uxZ8nUPOuig3Oyaa64ped8i7usFXXnllYX59ttvn5t17ty5po+zVJozZ05u9sorr+RmS+Ic9KLeEpGe7V4OC3Nfe9IMAAAJSjMAACQozQAAkKA0AwBAgtIMAAAJSjMAACQ0qesD1Dep0Tg77rhjblY0Ni5l7733zs2Kxsq99NJLhfsOHjy45DNBffL666/nZkbKLZyf/OQnudn111+fm6VGXxY58MADC/Mbb7yx5L2pOUWj/yIitthii9zsscceq+nj1Kmf//znuVnReMt11lmncN8pU6bkZnvssUdu1rdv38J9N95449zstddey83OP//8wn1btmyZm91+++2Fa5dUnjQDAECC0gwAAAlKMwAAJCjNAACQoDQDAECC0gwAAAlGzv2I0aNH52Ynnnhi4drmzZvX8GkWz6xZswrzuXPn1tJJgCVBhw4dcrMmTYp/S+jUqVNuVjRWbs6cOYX7HnnkkbnZDTfcULj2u+++K8xZMjz//PO5WdHosrZt2xbuWzSScPr06YVrU//fKtV7772Xmz366KO52XnnnVe472233VbSef74xz+WnBfd17/4xS8K9918881zs5122qlw7eWXX16Y1xVPmgEAIEFpBgCABKUZAAASlGYAAEhQmgEAIEFpBgCABKUZAAASGuSc5iFDhhTmI0eOzM2aNWtW08cpq759+xbmt956a252xhln5GYvvvhi4b5mp0L5dO3atTBfaaWVcrNx48blZquvvnqpR4pPP/00NzvllFMK11533XUlX5f64euvv87Niv79g9TvuUXzfIuuGRHx+uuvF+blkPq9c0nTpUuX3KxoDnPKTTfdVPLauuRJMwAAJCjNAACQoDQDAECC0gwAAAlKMwAAJCjNAACQUJFlWbZQb6yoKPdZas3HH39cmHfo0KEs1y36qb755psL195555252RZbbJGbbbvttoX7rrvuuoV5ntQIqaJxdQ3JQt5edWZJvK8rKytLylKKxiv+5S9/KVz74IMP5mZFo9ZSOnfunJsVjYv8xS9+Ubjv9ttvX/KZihR9raeddlpudumll5bjOHXGfU1DUTRWbtKkSSXve9dddxXmgwcPLnnvUi3Mfe1JMwAAJCjNAACQoDQDAECC0gwAAAlKMwAAJCjNAACQUK9Hzi233HK5WdHIs0MOOaRw30aN8v8sMX/+/MK19957b242fvz43Oy6664r3LdUyy67bGF+1lln5WaHH354bpYa/fWzn/0sN7v//vsL1y5NjKZadOUaObc4rrjiitzs/fffL3nftddeOzfbe++9S963yJVXXpmbpcZxfvDBB7lZ0c/R0sZ9TUNRrpFzKY0bNy7b3nmMnAMAgBqgNAMAQILSDAAACUozAAAkKM0AAJCgNAMAQILSDAAACU3q+gCLo0OHDrnZoYcempt9++23hfs+/fTTudlJJ51UuPaxxx4rzGvbl19+WZgXfT1FM1tPPvnkwn132WWX3KwhzWlm0S2JM2ZTs93L4eGHH87NbrnllpL3/dOf/pSbff755yXvCyx93n777dws1Xf69euXm1177bWlHqlOedIMAAAJSjMAACQozQAAkKA0AwBAgtIMAAAJSjMAACTU65Fzs2bNys0efPDB3Oy0004r3PfJJ58s+Uz1zezZs3Ozop+nd955p3Dff/3rXyWfiYZt6623zs169+6dm5177rllOM3iSd0nBx98cG42bdq03OzNN98s+UwAC+ujjz7KzV555ZXCtUUj54pGai7JPGkGAIAEpRkAABKUZgAASFCaAQAgQWkGAIAEpRkAABKUZgAASKjXc5pnzJiRm+244461eJKGZ9y4cXV9BJZSEyZMyM0mT56cm40fP77ka1544YWF+dVXX52bvfzyy7nZN998U7jvhx9+WJgDsOTwpBkAABKUZgAASFCaAQAgQWkGAIAEpRkAABKUZgAASKjIsixbqDdWVJT7LLDUWcjbq864r2HRua9h6bMw97UnzQAAkKA0AwBAgtIMAAAJSjMAACQozQAAkKA0AwBAgtIMAAAJSjMAACQozQAAkKA0AwBAgtIMAAAJSjMAACQozQAAkKA0AwBAgtIMAAAJSjMAACQozQAAkKA0AwBAgtIMAAAJSjMAACQozQAAkFCRZVlW14cAAIAlmSfNAACQoDQDAECC0gwAAAlKMwAAJCjNAACQoDQDAECC0gwAAAlKMwAAJCjNAACQ8P8AmR04+xGLu8wAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 900x900 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot more images\n",
    "torch.manual_seed(42)\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "rows, cols = 2, 3\n",
    "for i in range(1, rows * cols + 1):\n",
    "    random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
    "    img, label = train_data[random_idx]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    plt.title(class_names[label])\n",
    "    plt.axis(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPDzW0wxhi3"
   },
   "source": [
    "## 7. Turn the MNIST train and test datasets into dataloaders using `torch.utils.data.DataLoader`, set the `batch_size=32`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ALA6MPcFbJXQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x7fe251522ef0>, <torch.utils.data.dataloader.DataLoader object at 0x7fe251701090>)\n",
      "Length of train dataloader: 1875 batches of 32\n",
      "Length of test dataloader: 313 batches of 32\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Setup the batch size hyperparameter\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Turn datasets into iterables (batches)\n",
    "train_dataloader = DataLoader(train_data, # dataset to turn into iterable\n",
    "    batch_size=BATCH_SIZE, # how many samples per batch? \n",
    "    shuffle=True # shuffle data every epoch?\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False # don't necessarily have to shuffle the testing data\n",
    ")\n",
    "\n",
    "# Let's check out what we've created\n",
    "print(f\"Dataloaders: {train_dataloader, test_dataloader}\") \n",
    "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCCVfXk5xjYS"
   },
   "source": [
    "## 8. Recreate `model_2` used in notebook 03 (the same model from the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/), also known as TinyVGG) capable of fitting on the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "5IKNF22XbKYS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNISTModel(\n",
       "  (block_1): Sequential(\n",
       "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (block_2): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a convolutional neural network \n",
    "class MNISTModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Model architecture copying TinyVGG from: \n",
    "    https://poloclub.github.io/cnn-explainer/\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape, \n",
    "                      out_channels=hidden_units, \n",
    "                      kernel_size=3, # how big is the square that's going over the image?\n",
    "                      stride=1, # default\n",
    "                      padding=1),# options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units, \n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,\n",
    "                         stride=2) # default stride value is same as kernel_size\n",
    "        )\n",
    "        self.block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # Where did this in_features shape come from? \n",
    "            # It's because each layer of our network compresses and changes the shape of our input data.\n",
    "            nn.Linear(in_features=hidden_units*7*7, \n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.block_1(x)\n",
    "        # print(x.shape)\n",
    "        x = self.block_2(x)\n",
    "        # print(x.shape)\n",
    "        x = self.classifier(x)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model_2 = MNISTModel(input_shape=1, \n",
    "    hidden_units=10, \n",
    "    output_shape=len(class_names)).to(device)\n",
    "model_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sf_3zUr7xlhy"
   },
   "source": [
    "## 9. Train the model you built in exercise 8. for 5 epochs on CPU and GPU and see how long it takes on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "jSo6vVWFbNLD"
   },
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer \n",
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "    \"\"\"Prints difference between start and end time.\n",
    "\n",
    "    Args:\n",
    "        start (float): Start time of computation (preferred in timeit format). \n",
    "        end (float): End time of computation.\n",
    "        device ([type], optional): Device that compute is running on. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        float: time between start and end in seconds (higher is longer).\n",
    "    \"\"\"\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "    \"\"\"Calculates accuracy between truth labels and predictions.\n",
    "\n",
    "    Args:\n",
    "        y_true (torch.Tensor): Truth labels for predictions.\n",
    "        y_pred (torch.Tensor): Predictions to be compared to predictions.\n",
    "\n",
    "    Returns:\n",
    "        [torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45\n",
    "    \"\"\"\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_2.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.to(device)\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        # Send data to GPU\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Calculate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy_fn(y_true=y,\n",
    "                                 y_pred=y_pred.argmax(dim=1)) # Go from logits -> pred labels\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate loss and accuracy per epoch and print out what's happening\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "def test_step(data_loader: torch.utils.data.DataLoader,\n",
    "              model: torch.nn.Module,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device: torch.device = device):\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.to(device)\n",
    "    model.eval() # put model in eval mode\n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode(): \n",
    "        for X, y in data_loader:\n",
    "            # Send data to GPU\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            # 1. Forward pass\n",
    "            test_pred = model(X)\n",
    "            \n",
    "            # 2. Calculate loss and accuracy\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += accuracy_fn(y_true=y,\n",
    "                y_pred=test_pred.argmax(dim=1) # Go from logits -> pred labels\n",
    "            )\n",
    "        \n",
    "        # Adjust metrics and print out\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "---------\n",
      "Train loss: 0.33436 | Train accuracy: 88.73%\n",
      "Test loss: 0.07316 | Test accuracy: 97.67%\n",
      "\n",
      "Epoch: 1\n",
      "---------\n",
      "Train loss: 0.08233 | Train accuracy: 97.43%\n",
      "Test loss: 0.06682 | Test accuracy: 97.92%\n",
      "\n",
      "Epoch: 2\n",
      "---------\n",
      "Train loss: 0.06502 | Train accuracy: 97.99%\n",
      "Test loss: 0.05698 | Test accuracy: 98.11%\n",
      "\n",
      "Epoch: 3\n",
      "---------\n",
      "Train loss: 0.05625 | Train accuracy: 98.26%\n",
      "Test loss: 0.06048 | Test accuracy: 98.02%\n",
      "\n",
      "Epoch: 4\n",
      "---------\n",
      "Train loss: 0.05021 | Train accuracy: 98.43%\n",
      "Test loss: 0.04460 | Test accuracy: 98.47%\n",
      "\n",
      "Train time on cuda: 48.900 seconds\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Measure time\n",
    "from timeit import default_timer as timer\n",
    "train_time_start_on_gpu = timer()\n",
    "\n",
    "epochs = 5\n",
    "for epoch in (range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n---------\")\n",
    "    train_step(data_loader=train_dataloader, \n",
    "        model=model_2, \n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )\n",
    "    test_step(data_loader=test_dataloader,\n",
    "        model=model_2,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "train_time_end_on_gpu = timer()\n",
    "total_train_time_model_1 = print_train_time(start=train_time_start_on_gpu,\n",
    "                                            end=train_time_end_on_gpu,\n",
    "                                            device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model_2_cpu = MNISTModel(input_shape=1, \n",
    "    hidden_units=10, \n",
    "    output_shape=len(class_names))\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_2_cpu.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "---------\n",
      "Train loss: 0.33030 | Train accuracy: 88.92%\n",
      "Test loss: 0.08336 | Test accuracy: 97.43%\n",
      "\n",
      "Epoch: 1\n",
      "---------\n",
      "Train loss: 0.08572 | Train accuracy: 97.33%\n",
      "Test loss: 0.06483 | Test accuracy: 97.97%\n",
      "\n",
      "Epoch: 2\n",
      "---------\n",
      "Train loss: 0.06560 | Train accuracy: 97.94%\n",
      "Test loss: 0.05370 | Test accuracy: 98.19%\n",
      "\n",
      "Epoch: 3\n",
      "---------\n",
      "Train loss: 0.05558 | Train accuracy: 98.29%\n",
      "Test loss: 0.06176 | Test accuracy: 98.08%\n",
      "\n",
      "Epoch: 4\n",
      "---------\n",
      "Train loss: 0.04892 | Train accuracy: 98.47%\n",
      "Test loss: 0.04454 | Test accuracy: 98.58%\n",
      "\n",
      "Train time on cpu: 75.927 seconds\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Measure time\n",
    "from timeit import default_timer as timer\n",
    "train_time_start_on_cpu = timer()\n",
    "\n",
    "epochs = 5\n",
    "for epoch in (range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n---------\")\n",
    "    train_step(data_loader=train_dataloader, \n",
    "        model=model_2_cpu, \n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device='cpu'\n",
    "    )\n",
    "    test_step(data_loader=test_dataloader,\n",
    "        model=model_2_cpu,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device='cpu'\n",
    "    )\n",
    "\n",
    "train_time_end_on_cpu = timer()\n",
    "total_train_time_model_1 = print_train_time(start=train_time_start_on_cpu,\n",
    "                                            end=train_time_end_on_cpu,\n",
    "                                            device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1CsHhPpxp1w"
   },
   "source": [
    "## 10. Make predictions using your trained model and visualize at least 5 of them comparing the prediciton to the target label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "_YGgZvSobNxu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNISTModel(\n",
       "  (block_1): Sequential(\n",
       "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (block_2): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQwzqlBWxrpG"
   },
   "source": [
    "## 11. Plot a confusion matrix comparing your model's predictions to the truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vSrXiT_AbQ6e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lj6bDhoWxt2y"
   },
   "source": [
    "## 12. Create a random tensor of shape `[1, 3, 64, 64]` and pass it through a `nn.Conv2d()` layer with various hyperparameter settings (these can be any settings you choose), what do you notice if the `kernel_size` parameter goes up and down?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "leCTsqtSbR5P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHS20cNTxwSi"
   },
   "source": [
    "## 13. Use a model similar to the trained `model_2` from notebook 03 to make predictions on the test [`torchvision.datasets.FashionMNIST`](https://pytorch.org/vision/main/generated/torchvision.datasets.FashionMNIST.html) dataset. \n",
    "* Then plot some predictions where the model was wrong alongside what the label of the image should've been. \n",
    "* After visualing these predictions do you think it's more of a modelling error or a data error? \n",
    "* As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78a8LjtdbSZj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMUsDcN/+FAm9Pf7Ifqs6AZ",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "03_pytorch_computer_vision_exercises.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
